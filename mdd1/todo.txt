# Enviroment yourtts (i.e., DTW):
1. Prepare thhe MDD dataset: convert data/{train, dev, test, all, all_16k} to data-mdd/{all, train, dev, test}
    each directory should have 
        1. spk2utt,  2. text,  3.  utt2spk, 4.  wav.scp, 
        5. wav_ref.scp (reference waveform),
        6. wrd_text (word-level prompt),
        7. phn_text (phone-level annotation),
        8. transcript_phn_text (phone-level prompt)
        9. detection_targets (create by detection_targets)
        10. create transcript_phn_text with word boundaries

2. Align wav.scp and wav_ref.scp in data-mdd/{all, train, dev, test} with wrd_text and phn_text
    1. Create Directory textgrid in exp/mdd/{all, train, dev, test}/{org_align, ref_align}
    2. Leverage phonetic alignment toolkit (e.g., charsiu or ctc-segmentation) to create textgrid file textgrid/uttid.textgrid

4. Calculate DTW cost in each phone-level segmentation.
    1. Directly use of DTW cost
    2. Leveraging the DTW cost as a feature

5. Evaluate mispronunciation detection with F1 score.
    1. Global threshold
    2. Phone-dependency threshold
讀取數據：首先讀取三類文件：轉寫文本 (transcript_phn_text)、檢測目標 (detection_targets) 和 DTW 成本數據 (*.log 文件)。

預處理數據：將所有 phone 轉換為小寫，並忽略 'sil' 標籤。

組合數據：對於每個 utterance，將其轉寫文本、檢測目標和 DTW 成本關聯起來。

計算 F1 分數並找出最佳門檻：對每個 phone，計算不同 DTW 成本門檻下的 F1 分數，以找出最佳門檻。

判斷發音正確性：使用找到的最佳門檻來判斷每個 phone 的發音是否正確。

4. Future work
    1. Wav2vec2-mdd (reference waves)
